{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "import string\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn import svm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.neighbors import NearestNeighbors as KNN\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "from joblib import dump, load\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import gensim\n",
    "\n",
    "import torch\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import utils.BoW_data as dp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load train/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_file</th>\n",
       "      <th>resnet_vector</th>\n",
       "      <th>descriptions</th>\n",
       "      <th>tags</th>\n",
       "      <th>tags_values</th>\n",
       "      <th>tags_vec</th>\n",
       "      <th>word_list</th>\n",
       "      <th>word_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>images_train/5373.jpg</td>\n",
       "      <td>[-0.8994496464729309, -0.9304700493812561, -2....</td>\n",
       "      <td>[a red train is docked at the station, Several...</td>\n",
       "      <td>[vehicle:train, person:person, indoor:clock, a...</td>\n",
       "      <td>[train, person, clock, handbag]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[red, train, dock, station, sever, peopl, stan...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>images_train/984.jpg</td>\n",
       "      <td>[-1.3469539880752563, -3.1194605827331543, -0....</td>\n",
       "      <td>[A man with blue jersey holding a baseball bat...</td>\n",
       "      <td>[person:person, sports:baseball bat]</td>\n",
       "      <td>[person, baseball bat]</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[A, man, blue, jersey, hold, basebal, bat, clo...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>images_train/7127.jpg</td>\n",
       "      <td>[-3.44549822807312, -1.5245732069015503, -1.00...</td>\n",
       "      <td>[A kitchen decorated in red and white with acc...</td>\n",
       "      <td>[appliance:refrigerator, appliance:oven, appli...</td>\n",
       "      <td>[refriger, oven, sink, cup, cake, vase]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[A, kitchen, decor, red, white, accessori, A, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>images_train/9609.jpg</td>\n",
       "      <td>[1.1146496534347534, -2.1671018600463867, 0.09...</td>\n",
       "      <td>[A black and white dog chasing sheep in a fiel...</td>\n",
       "      <td>[animal:dog, animal:sheep]</td>\n",
       "      <td>[dog, sheep]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[A, black, white, dog, chase, sheep, field, sm...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>images_train/5293.jpg</td>\n",
       "      <td>[1.6026496887207031, -1.5058174133300781, 3.02...</td>\n",
       "      <td>[Two bears with their mouths open in the water...</td>\n",
       "      <td>[animal:bear]</td>\n",
       "      <td>[bear]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[two, bear, mouth, open, water, A, coupl, bear...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              image_file                                      resnet_vector  \\\n",
       "0  images_train/5373.jpg  [-0.8994496464729309, -0.9304700493812561, -2....   \n",
       "1   images_train/984.jpg  [-1.3469539880752563, -3.1194605827331543, -0....   \n",
       "2  images_train/7127.jpg  [-3.44549822807312, -1.5245732069015503, -1.00...   \n",
       "3  images_train/9609.jpg  [1.1146496534347534, -2.1671018600463867, 0.09...   \n",
       "4  images_train/5293.jpg  [1.6026496887207031, -1.5058174133300781, 3.02...   \n",
       "\n",
       "                                        descriptions  \\\n",
       "0  [a red train is docked at the station, Several...   \n",
       "1  [A man with blue jersey holding a baseball bat...   \n",
       "2  [A kitchen decorated in red and white with acc...   \n",
       "3  [A black and white dog chasing sheep in a fiel...   \n",
       "4  [Two bears with their mouths open in the water...   \n",
       "\n",
       "                                                tags  \\\n",
       "0  [vehicle:train, person:person, indoor:clock, a...   \n",
       "1               [person:person, sports:baseball bat]   \n",
       "2  [appliance:refrigerator, appliance:oven, appli...   \n",
       "3                         [animal:dog, animal:sheep]   \n",
       "4                                      [animal:bear]   \n",
       "\n",
       "                               tags_values  \\\n",
       "0          [train, person, clock, handbag]   \n",
       "1                   [person, baseball bat]   \n",
       "2  [refriger, oven, sink, cup, cake, vase]   \n",
       "3                             [dog, sheep]   \n",
       "4                                   [bear]   \n",
       "\n",
       "                                            tags_vec  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                           word_list  \\\n",
       "0  [red, train, dock, station, sever, peopl, stan...   \n",
       "1  [A, man, blue, jersey, hold, basebal, bat, clo...   \n",
       "2  [A, kitchen, decor, red, white, accessori, A, ...   \n",
       "3  [A, black, white, dog, chase, sheep, field, sm...   \n",
       "4  [two, bear, mouth, open, water, A, coupl, bear...   \n",
       "\n",
       "                                         word_vector  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddir = 'data/'\n",
    "\n",
    "mlb_tags_train, mlb_tags_test, df = dp.load_dataframe()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_file</th>\n",
       "      <th>resnet_vector</th>\n",
       "      <th>descriptions</th>\n",
       "      <th>tags</th>\n",
       "      <th>tags_values</th>\n",
       "      <th>tags_vec</th>\n",
       "      <th>word_list</th>\n",
       "      <th>word_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>images_test/152.jpg</td>\n",
       "      <td>[-0.148756742477417, -0.4813389182090759, -0.6...</td>\n",
       "      <td>[A sign sitting above a store front entrance.,...</td>\n",
       "      <td>[person:person]</td>\n",
       "      <td>[person]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[A, sign, sit, store, front, entranc, small, a...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>images_test/901.jpg</td>\n",
       "      <td>[-2.7743351459503174, -2.609677791595459, -2.2...</td>\n",
       "      <td>[A steam locamotive passes by some houses on a...</td>\n",
       "      <td>[indoor:clock]</td>\n",
       "      <td>[clock]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[A, steam, locamot, pass, hous, track, A, smal...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>images_test/1609.jpg</td>\n",
       "      <td>[-4.7030134201049805, -3.1210086345672607, -0....</td>\n",
       "      <td>[a woman with purple hair is taking a picture ...</td>\n",
       "      <td>[animal:dog, animal:horse, person:person]</td>\n",
       "      <td>[dog, hors, person]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[woman, purpl, hair, take, pictur, A, hipster,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>images_test/501.jpg</td>\n",
       "      <td>[-4.7203192710876465, -3.283935546875, -3.4253...</td>\n",
       "      <td>[A GREEN AND BROWN SUITCASE LYING UP ON A LEDG...</td>\n",
       "      <td>[furniture:toilet]</td>\n",
       "      <td>[toilet]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[A, green, and, brown, suitcas, ly, UP, ON, A,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>images_test/517.jpg</td>\n",
       "      <td>[-2.5421407222747803, 0.7139833569526672, -4.4...</td>\n",
       "      <td>[A desk with a small white computer set up on ...</td>\n",
       "      <td>[animal:cat, kitchen:bowl, furniture:bed]</td>\n",
       "      <td>[cat, bowl, bed]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "      <td>[A, desk, small, white, comput, set, A, desk, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             image_file                                      resnet_vector  \\\n",
       "0   images_test/152.jpg  [-0.148756742477417, -0.4813389182090759, -0.6...   \n",
       "1   images_test/901.jpg  [-2.7743351459503174, -2.609677791595459, -2.2...   \n",
       "2  images_test/1609.jpg  [-4.7030134201049805, -3.1210086345672607, -0....   \n",
       "3   images_test/501.jpg  [-4.7203192710876465, -3.283935546875, -3.4253...   \n",
       "4   images_test/517.jpg  [-2.5421407222747803, 0.7139833569526672, -4.4...   \n",
       "\n",
       "                                        descriptions  \\\n",
       "0  [A sign sitting above a store front entrance.,...   \n",
       "1  [A steam locamotive passes by some houses on a...   \n",
       "2  [a woman with purple hair is taking a picture ...   \n",
       "3  [A GREEN AND BROWN SUITCASE LYING UP ON A LEDG...   \n",
       "4  [A desk with a small white computer set up on ...   \n",
       "\n",
       "                                        tags          tags_values  \\\n",
       "0                            [person:person]             [person]   \n",
       "1                             [indoor:clock]              [clock]   \n",
       "2  [animal:dog, animal:horse, person:person]  [dog, hors, person]   \n",
       "3                         [furniture:toilet]             [toilet]   \n",
       "4  [animal:cat, kitchen:bowl, furniture:bed]     [cat, bowl, bed]   \n",
       "\n",
       "                                            tags_vec  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, ...   \n",
       "\n",
       "                                           word_list  \\\n",
       "0  [A, sign, sit, store, front, entranc, small, a...   \n",
       "1  [A, steam, locamot, pass, hous, track, A, smal...   \n",
       "2  [woman, purpl, hair, take, pictur, A, hipster,...   \n",
       "3  [A, green, and, brown, suitcas, ly, UP, ON, A,...   \n",
       "4  [A, desk, small, white, comput, set, A, desk, ...   \n",
       "\n",
       "                                         word_vector  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb_tags_train2, mlb_tags_test2, df_test = dp.load_dataframe(train_or_test='test')\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have to do this because load_dataframe() is messing up resnet_vectors somehow\n",
    "with open('data/features_train/features_resnet1000_train.csv', 'r') as fp:\n",
    "    features_train = [x.strip().split(',') for x in fp.readlines()]\n",
    "    \n",
    "features_train = {x[0]: np.array([np.float(n) for n in x[1:]]) for x in features_train}\n",
    "\n",
    "with open('data/features_test/features_resnet1000_test.csv', 'r') as fp:\n",
    "    features_test = [x.strip().split(',') for x in fp.readlines()]\n",
    "    \n",
    "features_test = {x[0]: np.array([np.float64(n) for n in x[1:]]) for x in features_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have to do this because load_dataframe() is messing up resnet_vectors somehow\n",
    "with open('data/features_train/features_resnet1000intermediate_train.csv', 'r') as fp:\n",
    "    int_features_train = [x.strip().split(',') for x in fp.readlines()]\n",
    "    \n",
    "int_features_train = {x[0]: np.array([np.float(n) for n in x[1:]]) for x in int_features_train}\n",
    "\n",
    "# Have to do this because load_dataframe() is messing up resnet_vectors somehow\n",
    "with open('data/features_test/features_resnet1000intermediate_test.csv', 'r') as fp:\n",
    "    int_features_test = [x.strip().split(',') for x in fp.readlines()]\n",
    "    \n",
    "int_features_test = {x[0]: np.array([np.float64(n) for n in x[1:]]) for x in int_features_test}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['desc_joined'] = df['descriptions'].apply(lambda x: \" \".join(x).split(\" \"))\n",
    "df_test['desc_joined'] = df_test['descriptions'].apply(lambda x: \" \".join(x).split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = gensim.models.KeyedVectors.load_word2vec_format('./models/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.remove('not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word2vec(df_in, wmodel):\n",
    "    \n",
    "    def prep_doc(doc):\n",
    "\n",
    "        # Stem and lower all the words\n",
    "        sentence = [\n",
    "            ps.stem(word).lower() for word in doc\n",
    "        ]\n",
    "\n",
    "        # Remove trailing commas and periods\n",
    "        sentence = [\n",
    "            \"\".join([char for char in word if char not in string.punctuation]) for word in sentence\n",
    "        ]\n",
    "\n",
    "        # Remove stopwords, remove any blank words \n",
    "        sentence = [\n",
    "            word for word in sentence if word not in stop_words and word not in  [\" \", \"\"]\n",
    "        ]\n",
    "        \n",
    "        return sentence\n",
    "    \n",
    "    def try_get_vec(word):\n",
    "        try:\n",
    "            word = wmodel.get_vector(word)\n",
    "            can_do = True\n",
    "        except:\n",
    "            word = np.zeros(300)\n",
    "            can_do = False\n",
    "        return can_do\n",
    "    \n",
    "    def get_vector(word):\n",
    "        try:\n",
    "            word = wmodel.get_vector(word)\n",
    "        except:\n",
    "            word = np.zeros(300)\n",
    "        return word\n",
    "    \n",
    "    stops = set(stopwords.words('english'))\n",
    "    vecs = df_in['desc_joined'].apply(\n",
    "        lambda desc: np.average([\n",
    "            get_vector(word) for word in prep_doc(desc)\n",
    "            if try_get_vec(word)\n",
    "        ], axis=0)\n",
    "    )\n",
    "    \n",
    "    return np.asarray([vec for vec in vecs], dtype=np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray([features_train[x] for x in df['image_file']], dtype=np.float64)\n",
    "y = get_word2vec(df, w2v_model)\n",
    "\n",
    "y_true = df['image_file'].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi output is super slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputRegressor(estimator=SGDRegressor(alpha=0.0001, average=False,\n",
       "                                            early_stopping=False, epsilon=0.1,\n",
       "                                            eta0=0.01, fit_intercept=True,\n",
       "                                            l1_ratio=0.15,\n",
       "                                            learning_rate='invscaling',\n",
       "                                            loss='squared_loss', max_iter=1000,\n",
       "                                            n_iter_no_change=5, penalty='l2',\n",
       "                                            power_t=0.25, random_state=None,\n",
       "                                            shuffle=True, tol=0.001,\n",
       "                                            validation_fraction=0.1, verbose=0,\n",
       "                                            warm_start=False),\n",
       "                     n_jobs=None)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi = MultiOutputRegressor(SGDRegressor())\n",
    "\n",
    "multi.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.5884428211637805e+23"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputRegressor(estimator=SVR(C=100, cache_size=200, coef0=1, degree=3,\n",
       "                                   epsilon=0.1, gamma='auto', kernel='poly',\n",
       "                                   max_iter=-1, shrinking=True, tol=0.001,\n",
       "                                   verbose=False),\n",
       "                     n_jobs=None)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi = MultiOutputRegressor(SVR(kernel='poly', C=100, gamma='auto', degree=3, epsilon=.1,\n",
    "               coef0=1))\n",
    "\n",
    "multi.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31295815966301227"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi = MultiOutputRegressor(AdaBoostRegressor(random_state=0, n_estimators=100))\n",
    "\n",
    "multi.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi SVR - 0.312"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KernelRidge(alpha=1, coef0=1, degree=4, gamma=None, kernel='linear',\n",
       "            kernel_params=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = KernelRidge(degree=4)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.40801693389570415"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.408 KernelRidge(degree=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel Ridge RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KernelRidge(alpha=1, coef0=1, degree=4, gamma=None, kernel=RBF(length_scale=1),\n",
       "            kernel_params=None)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = KernelRidge(kernel=RBF(40), alpha=1, degree=4)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.8970433109869271"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KernelRidge(alpha=1, coef0=1, degree=4, gamma=None, kernel='rbf',\n",
       "            kernel_params=None)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_lin = KernelRidge(alpha=1, degree=4, kernel='rbf')\n",
    "clf_lin.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.30244644483222466"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_lin.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PLSRegression(copy=True, max_iter=500, n_components=2, scale=True, tol=1e-06)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pls = PLSRegression()\n",
    "pls.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.10463092507910798"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pls.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparam tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'kernel':('linear', RBF(0.5), RBF(1), RBF(2), Matern(1)),\n",
    "    'alpha':[0.1, 1, 10],\n",
    "    'degree': [3,4,5]\n",
    "}\n",
    "\n",
    "hyper = GridSearchCV(KernelRidge(), parameters, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hyper.best_params_)\n",
    "\n",
    "y_true, y_pred = y_test, hyper.predict(X_test)\n",
    "classification_report(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingRegressor(estimators=[('lr',\n",
       "                             KernelRidge(alpha=1, coef0=1, degree=4, gamma=None,\n",
       "                                         kernel='linear', kernel_params=None)),\n",
       "                            ('rf',\n",
       "                             PLSRegression(copy=True, max_iter=500,\n",
       "                                           n_components=2, scale=True,\n",
       "                                           tol=1e-06))],\n",
       "                n_jobs=None, weights=None)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1 = KernelRidge(alpha=1, degree=4)\n",
    "r2 = PLSRegression()\n",
    "\n",
    "er = VotingRegressor([('lr', r1), ('rf', r2)])\n",
    "mer = MultiOutputRegressor(er)\n",
    "mer.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [2000, 300]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-8512d13f00ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;31m# XXX: Remove the check in 0.23\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m         \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_reg_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'continuous-multioutput'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m             warnings.warn(\"The default value of multioutput (not exposed in \"\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/metrics/regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \"\"\"\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 205\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2000, 300]"
     ]
    }
   ],
   "source": [
    "er.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 1000)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingRegressor(base_estimator=KernelRidge(alpha=1, coef0=1, degree=4,\n",
       "                                            gamma=None, kernel='linear',\n",
       "                                            kernel_params=None),\n",
       "                 bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "                 max_samples=1.0, n_estimators=10, n_jobs=None, oob_score=False,\n",
       "                 random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = BaggingRegressor(base_estimator=KernelRidge(alpha=1, degree=4),\n",
    "                         n_estimators=10, random_state=0).fit(X, y)\n",
    "\n",
    "regr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4033278594844159"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = KernelRidge(alpha=1, degree=4)\n",
    "r2 = MultiOutputRegressor(SVR(kernel='poly', C=100, gamma='auto', degree=3, epsilon=.1,\n",
    "               coef0=1))\n",
    "\n",
    "er = VotingRegressor([('lr', r1), ('rf', r2)])\n",
    "er.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "er.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "solvers = ['lbfgs', 'sgd', 'adam']\n",
    "\n",
    "nn = MLPRegressor(\n",
    "    hidden_layer_sizes=(1024, 512),\n",
    "    max_iter=300,\n",
    "    solver='adam',\n",
    "    activation='relu',\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.04762700\n",
      "Iteration 2, loss = 0.00354088\n",
      "Iteration 3, loss = 0.00291076\n",
      "Iteration 4, loss = 0.00250705\n",
      "Iteration 5, loss = 0.00226912\n",
      "Iteration 6, loss = 0.00213586\n",
      "Iteration 7, loss = 0.00206379\n",
      "Iteration 8, loss = 0.00202600\n",
      "Iteration 9, loss = 0.00200665\n",
      "Iteration 10, loss = 0.00199700\n",
      "Iteration 11, loss = 0.00199231\n",
      "Iteration 12, loss = 0.00199009\n",
      "Iteration 13, loss = 0.00198903\n",
      "Iteration 14, loss = 0.00198858\n",
      "Iteration 15, loss = 0.00198837\n",
      "Iteration 16, loss = 0.00198829\n",
      "Iteration 17, loss = 0.00198825\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "             hidden_layer_sizes=(1024, 512), learning_rate='constant',\n",
       "             learning_rate_init=0.001, max_iter=300, momentum=0.9,\n",
       "             n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "             random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "             validation_fraction=0.1, verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.0013719643188388727"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_prediction(true, pred):\n",
    "\n",
    "    if true not in pred:\n",
    "        return 0.0\n",
    "    \n",
    "    ind = pred.index(true)\n",
    "    \n",
    "    return (20 - ind) / 20\n",
    "\n",
    "\n",
    "def nearest_neighbors(sample, targets):\n",
    "    \"\"\"Returns index positions of nearest neighbors\"\"\"\n",
    "    distances = [np.linalg.norm(t-sample) for t in targets]\n",
    "    distances_sorted = np.argsort(distances)\n",
    "    return distances_sorted[:20]\n",
    "\n",
    "\n",
    "def furthest_neighbors(sample, targets):\n",
    "    \"\"\"Returns index positions of nearest neighbors\"\"\"\n",
    "    distances = [np.linalg.norm(t-sample) for t in targets]\n",
    "    distances_sorted = np.argsort(distances)\n",
    "    return distances_sorted[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_embeddings = [model.predict(vec.reshape(1, -1)) for vec in X_test]\n",
    "pred_indices = [nearest_neighbors(sample, pred_embeddings) for sample in y_test]\n",
    "\n",
    "preds = [\n",
    "    [y_true[ind] for ind in pred]\n",
    "    for pred in pred_indices\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = sum(\n",
    "    [score_prediction(y_true[ind], pred) for ind, pred in enumerate(preds)]\n",
    "           ) / len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5686250000000019\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resout = np.asarray([features_test[x] for x in df_test['image_file']], dtype=np.float64)\n",
    "decout = get_word2vec(df_test, w2v_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_embeddings = [model.predict(vec.reshape(1, -1)) for vec in resout]\n",
    "test_pred_indices = [nearest_neighbors(sample, test_pred_embeddings) for sample in decout]\n",
    "\n",
    "y_targets = df_test['image_file'].to_numpy()\n",
    "\n",
    "preds = [\n",
    "    [y_targets[ind] for ind in pred]\n",
    "    for pred in test_pred_indices\n",
    "]\n",
    "\n",
    "preds = [[file.split('/')[-1] for file in pred] for pred in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_txt_files = df_test['image_file'].apply(\n",
    "        lambda x: x.split('/')[-1].replace('jpg', 'txt')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_preds = list(zip(desc_txt_files.to_numpy(), preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('regr.csv', 'w+') as f:\n",
    "    f.write('Descritpion_ID,Top_20_Image_IDs\\n')\n",
    "    for pred in out_preds:\n",
    "        f.write(f\"{pred[0]},{' '.join(pred[1])}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
