{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mdescriptions_test\u001b[m\u001b[m     \u001b[34mfeatures_train\u001b[m\u001b[m        sample_submission.csv\r\n",
      "\u001b[34mdescriptions_train\u001b[m\u001b[m    \u001b[34mimages_test\u001b[m\u001b[m           \u001b[34mtags_test\u001b[m\u001b[m\r\n",
      "\u001b[34mfeatures_test\u001b[m\u001b[m         \u001b[34mimages_train\u001b[m\u001b[m          \u001b[34mtags_train\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score as cv\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "import gensim\n",
    "\n",
    "from utils.data_parsers import load_dataframe as ld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = ld()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_file</th>\n",
       "      <th>resnet_vector</th>\n",
       "      <th>descriptions</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>images_train/5373.jpg</td>\n",
       "      <td>[-0.8994496464729309, -0.9304700493812561, -2....</td>\n",
       "      <td>[a red train is docked at the station, Several...</td>\n",
       "      <td>[vehicle:train, person:person, indoor:clock, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>images_train/984.jpg</td>\n",
       "      <td>[-1.3469539880752563, -3.1194605827331543, -0....</td>\n",
       "      <td>[A man with blue jersey holding a baseball bat...</td>\n",
       "      <td>[person:person, sports:baseball bat]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>images_train/7127.jpg</td>\n",
       "      <td>[-3.44549822807312, -1.5245732069015503, -1.00...</td>\n",
       "      <td>[A kitchen decorated in red and white with acc...</td>\n",
       "      <td>[appliance:refrigerator, appliance:oven, appli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>images_train/9609.jpg</td>\n",
       "      <td>[1.1146496534347534, -2.1671018600463867, 0.09...</td>\n",
       "      <td>[A black and white dog chasing sheep in a fiel...</td>\n",
       "      <td>[animal:dog, animal:sheep]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>images_train/5293.jpg</td>\n",
       "      <td>[1.6026496887207031, -1.5058174133300781, 3.02...</td>\n",
       "      <td>[Two bears with their mouths open in the water...</td>\n",
       "      <td>[animal:bear]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              image_file                                      resnet_vector  \\\n",
       "0  images_train/5373.jpg  [-0.8994496464729309, -0.9304700493812561, -2....   \n",
       "1   images_train/984.jpg  [-1.3469539880752563, -3.1194605827331543, -0....   \n",
       "2  images_train/7127.jpg  [-3.44549822807312, -1.5245732069015503, -1.00...   \n",
       "3  images_train/9609.jpg  [1.1146496534347534, -2.1671018600463867, 0.09...   \n",
       "4  images_train/5293.jpg  [1.6026496887207031, -1.5058174133300781, 3.02...   \n",
       "\n",
       "                                        descriptions  \\\n",
       "0  [a red train is docked at the station, Several...   \n",
       "1  [A man with blue jersey holding a baseball bat...   \n",
       "2  [A kitchen decorated in red and white with acc...   \n",
       "3  [A black and white dog chasing sheep in a fiel...   \n",
       "4  [Two bears with their mouths open in the water...   \n",
       "\n",
       "                                                tags  \n",
       "0  [vehicle:train, person:person, indoor:clock, a...  \n",
       "1               [person:person, sports:baseball bat]  \n",
       "2  [appliance:refrigerator, appliance:oven, appli...  \n",
       "3                         [animal:dog, animal:sheep]  \n",
       "4                                      [animal:bear]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tags_to_list(fp):\n",
    "    \n",
    "    with open(fp) as f:\n",
    "        tags = f.readlines()\n",
    "\n",
    "    return [tag.strip() for tag in tags]\n",
    "\n",
    "\n",
    "def get_tags(df, train_or_test='train', imfile_column='image_file'):\n",
    "    \"\"\"Returns pandas series of image tags\"\"\"\n",
    "    \n",
    "    return df[imfile_column].apply(\n",
    "        lambda x: extract_tags_to_list(\n",
    "            f'data/tags_{train_or_test}/' + x.split('/')[-1].replace('jpg', 'txt')\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def extract_tags_to_list_split(fp):\n",
    "    \n",
    "    with open(fp) as f:\n",
    "        tags = f.readlines()\n",
    "        \n",
    "    tag_pairs = [tag.strip().split(':') for tag in tags]\n",
    "    \n",
    "    higher_cat = [x[0] for x in tag_pairs]\n",
    "    lower_cat = [x[0] for x in tag_pairs]\n",
    "\n",
    "    return higher_cat, lower_cat\n",
    "\n",
    "\n",
    "def get_tags_split(df, train_or_test='train', imfile_column='image_file'):\n",
    "    \"\"\"Returns two pandas series of image tags, higher and lower category\"\"\"\n",
    "    \n",
    "    return zip(*df[imfile_column].map(\n",
    "        lambda x: extract_tags_to_list_split(\n",
    "            f'data/tags_{train_or_test}/' + x.split('/')[-1].replace('jpg', 'txt')\n",
    "        )\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/descriptions_train/0.txt') as f:\n",
    "    x = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_description(fp):\n",
    "    with open(fp) as f:\n",
    "        descriptions = [x.strip() for x in f.readlines()]\n",
    "        \n",
    "    return descriptions\n",
    "\n",
    "def get_descriptions(df, train_or_test='train', imfile_column='image_file'):\n",
    "    \"\"\"Descriptions are independant? lists of line by line description\"\"\"\n",
    "    return df[imfile_column].apply(\n",
    "        lambda x: open_description(f'data/descriptions_{train_or_test}/' + x.split('/')[-1].replace('jpg', 'txt'))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "descs = get_descriptions(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resnet_features(train_or_test='train'):\n",
    "    \"\"\"Gets image_id -> 1000 dim feature vector\"\"\"\n",
    "    \n",
    "    fp = f'data/features_{train_or_test}/features_resnet1000_{train_or_test}.csv'\n",
    "    lines = []\n",
    "    \n",
    "    with open(fp) as f:\n",
    "        line = f.readline()\n",
    "        while line:\n",
    "            line = line.split(',')\n",
    "            lines.append({\"image_file\": line[0], \"resnet_vector\": np.array([np.double(x.strip()) for x in line[1:]])})\n",
    "            line = f.readline()\n",
    "            \n",
    "\n",
    "            return lines\n",
    "\n",
    "\n",
    "def get_resnet_intermediate_features(train_or_test='train'):\n",
    "    \"\"\"Gets image_id -> 2048 dim intermediate feature vector\"\"\"\n",
    "    \n",
    "    fp = f'data/features_{train_or_test}/features_resnet1000intermediate_{train_or_test}.csv'\n",
    "    lines = []\n",
    "\n",
    "    with open(fp) as f:\n",
    "        line = f.readline()\n",
    "        while line:\n",
    "            line = line.split(',')\n",
    "            lines.append({\"image_file\": line[0], \"resnet_vector\": np.array([np.double(x.strip()) for x in line[1:]])})\n",
    "            line = f.readline()\n",
    "            \n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = get_resnet_features()\n",
    "features_int = get_resnet_intermediate_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [vehicle:train, person:person, indoor:clock, a...\n",
       "Name: image_file, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_tags(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format('./models/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word2vec(df, model, desc_column='descriptions'):\n",
    "    vecs = df[desc_column].apply(\n",
    "        lambda x: model.get_vector(x)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_join = descs.apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    a red train is docked at the station Several p...\n",
       "Name: image_file, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc_join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying naive bayes to BOW representation of description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_file</th>\n",
       "      <th>resnet_vector</th>\n",
       "      <th></th>\n",
       "      <th>.</th>\n",
       "      <th>A</th>\n",
       "      <th>S</th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>...</th>\n",
       "      <th>m</th>\n",
       "      <th>n</th>\n",
       "      <th>o</th>\n",
       "      <th>p</th>\n",
       "      <th>r</th>\n",
       "      <th>s</th>\n",
       "      <th>t</th>\n",
       "      <th>v</th>\n",
       "      <th>w</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>images_train/5373.jpg</td>\n",
       "      <td>[-0.8994496464729309, -0.9304700493812561, -2....</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              image_file                                      resnet_vector  \\\n",
       "0  images_train/5373.jpg  [-0.8994496464729309, -0.9304700493812561, -2....   \n",
       "\n",
       "      .  A  S  a  b  c  d  ...  m  n  o  p  r  s  t  v  w  y  \n",
       "0  1  1  1  1  1  1  1  1  ...  1  1  1  1  1  1  1  1  1  1  \n",
       "\n",
       "[1 rows x 27 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "one_hot_encodings = mlb.fit_transform(desc_join)\n",
    "one_hot_columns = mlb.classes_\n",
    "\n",
    "train_one_hot = df.join(\n",
    "    pd.DataFrame(\n",
    "        one_hot_encodings,\n",
    "        columns=one_hot_columns,\n",
    "        index=df.index\n",
    "    ))\n",
    "\n",
    "train_one_hot = train_one_hot\n",
    "\n",
    "train_one_hot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
